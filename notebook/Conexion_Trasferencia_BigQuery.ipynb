import os
from dotenv import load_dotenv
import pandas as pd
from sqlalchemy import create_engine
from pandas_gbq import to_gbq

# Cargar variables
load_dotenv()

# MYSQL
usuario = os.getenv("MYSQL_USER")
password = os.getenv("MYSQL_PASSWORD")
host = os.getenv("MYSQL_HOST")
db = os.getenv("MYSQL_DATABASE")
puerto = os.getenv("MYSQL_PORT")

# GCP
proyecto_id = os.getenv("GCP_PROJECT_ID")
dataset_bq = "nba_dataset"        # dataset en la nube
tabla_bq = "lesiones"             # Nombre de tabla destino en BigQuery
ruta_credenciales = "credenciales.json"

# Autenticación con GCP
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = ruta_credenciales

# Crear conexión a MySQL
engine = create_engine(f'mysql+mysqlconnector://{usuario}:{password}@{host}:{puerto}/{db}')

# Leer tabla desde MySQL
df = pd.read_sql("SELECT * FROM lesiones", con=engine)
print(f"✔ Filas leídas desde MySQL: {df.shape[0]}")

# Enviar a BigQuery
to_gbq(
    dataframe=df,
    destination_table=f"{dataset_bq}.{tabla_bq}",
    project_id=proyecto_id,
    if_exists='replace'
)

print("Tabla 'lesiones' cargada correctamente en BigQuery.")
